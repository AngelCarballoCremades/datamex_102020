{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised classification\n",
    "\n",
    "In the data.csv there are letters (uppercases and lowercases) and numbers, 28x28 pixels in a row format.\n",
    "\n",
    "* First, you need to know which labels are which, meaning you need to visualize some data to realize which number labels represents a letter, or a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "df = pd.read_csv('data_all.csv', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>upper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      e    1    2    3    4    5    6    7    8    9  ...  776  777  778  779  \\\n",
       "0  36.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2   3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  33.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  30.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   780  781  782  783  784    type  \n",
       "0  0.0  0.0  0.0  0.0  0.0   lower  \n",
       "1  0.0  0.0  0.0  0.0  0.0  number  \n",
       "2  0.0  0.0  0.0  0.0  0.0  number  \n",
       "3  0.0  0.0  0.0  0.0  0.0   upper  \n",
       "4  0.0  0.0  0.0  0.0  0.0   upper  \n",
       "\n",
       "[5 rows x 786 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.0\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(df.iloc[115581,1:].values.reshape(28,28))  \n",
    "plt.show()\n",
    "print(df.iloc[115581,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classif(x):\n",
    "    if 0.0<=x<=9.0:\n",
    "        return 'number'\n",
    "    \n",
    "    elif 10.0<=x<=35.0:\n",
    "        return 'upper'\n",
    "    \n",
    "    elif 36.0<=x<=61.0:\n",
    "        return 'lower'\n",
    "    \n",
    "    else:\n",
    "        return 'ERR'\n",
    "    \n",
    "\n",
    "df['type'] = df.e.apply(classif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, try to train a classifier model to predict the uppercases. Use every single model you know for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_letters = df[df.type == 'upper']\n",
    "lower_letters = df[df.type == 'lower']\n",
    "numbers = df[df.type == 'number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=2000) done.\n",
      "RandomForestClassifier() done.\n",
      "SVC() done.\n",
      "LogisticRegression(max_iter=2000) 0.7157441378210241\n",
      "RandomForestClassifier() 0.9065241665337375\n",
      "SVC() 0.9318870633274845\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(upper_letters.drop(columns=['type', 'e']), upper_letters.e, train_size = 0.8)\n",
    "\n",
    "model1 = LogisticRegression(max_iter = 2000,)\n",
    "model1.fit(X_train, y_train)\n",
    "print(str(model1), 'done.')\n",
    "\n",
    "model2 = RandomForestClassifier(n_estimators = 100)\n",
    "model2.fit(X_train, y_train)\n",
    "print(str(model2), 'done.')\n",
    "\n",
    "model3 = SVC()\n",
    "model3.fit(X_train, y_train)\n",
    "print(str(model3), 'done.')\n",
    "\n",
    "print(str(model1), model1.score(X_test, y_test))\n",
    "print(str(model2), model2.score(X_test, y_test))\n",
    "print(str(model3), model3.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Try to do the same thing with lowercases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=2000) done.\n",
      "RandomForestClassifier() done.\n",
      "SVC() done.\n",
      "LogisticRegression(max_iter=2000) 0.684589800443459\n",
      "RandomForestClassifier() 0.881559497413156\n",
      "SVC() 0.9041019955654102\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "X_train, X_test, y_train, y_test = train_test_split(lower_letters.drop(columns=['type', 'e']), lower_letters.e, train_size = 0.8)\n",
    "\n",
    "model1 = LogisticRegression(max_iter = 2000,)\n",
    "model1.fit(X_train, y_train)\n",
    "print(str(model1), 'done.')\n",
    "\n",
    "model2 = RandomForestClassifier(n_estimators = 100)\n",
    "model2.fit(X_train, y_train)\n",
    "print(str(model2), 'done.')\n",
    "\n",
    "model3 = SVC()\n",
    "model3.fit(X_train, y_train)\n",
    "print(str(model3), 'done.')\n",
    "\n",
    "print(str(model1), model1.score(X_test, y_test))\n",
    "print(str(model2), model2.score(X_test, y_test))\n",
    "print(str(model3), model3.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Try to do the same thing with numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Angel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=2000) done.\n",
      "RandomForestClassifier() done.\n",
      "SVC() done.\n",
      "LogisticRegression(max_iter=2000) 0.9182493093922652\n",
      "RandomForestClassifier() 0.9699585635359116\n",
      "SVC() 0.981871546961326\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "X_train, X_test, y_train, y_test = train_test_split(numbers.drop(columns=['type', 'e']), numbers.e, train_size = 0.8)\n",
    "\n",
    "model1 = LogisticRegression(max_iter = 2000,)\n",
    "model1.fit(X_train, y_train)\n",
    "print(str(model1), 'done.')\n",
    "\n",
    "model2 = RandomForestClassifier(n_estimators = 100)\n",
    "model2.fit(X_train, y_train)\n",
    "print(str(model2), 'done.')\n",
    "\n",
    "model3 = SVC()\n",
    "model3.fit(X_train, y_train)\n",
    "print(str(model3), 'done.')\n",
    "\n",
    "print(str(model1), model1.score(X_test, y_test))\n",
    "print(str(model2), model2.score(X_test, y_test))\n",
    "print(str(model3), model3.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC had the best score in all 3 scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
